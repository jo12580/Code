{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.9 反向传播的实现 -回归-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.9.5 完整的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -- 准备输入和正确答案数据 --\n",
    "input_data = np.arange(0, np.pi*2, 0.1)  # 输入\n",
    "correct_data = np.sin(input_data)  # 正确答案\n",
    "input_data = (input_data-np.pi)/np.pi  # 将输入收敛到-1.0-1.0的范围之内\n",
    "n_data = len(correct_data)  # 数据的数量\n",
    "\n",
    "# -- 各个设定值 --\n",
    "n_in = 1  # 输入层的神经元数量\n",
    "n_mid = 3  # 中间层的神经元数量\n",
    "n_out = 1  # 输出层的神经元数量\n",
    "\n",
    "wb_width = 0.01  # 权重和偏置的扩散程度\n",
    "eta = 0.1  # 学习系数\n",
    "epoch = 2001\n",
    "interval = 200  # 显示进度的间隔实践\n",
    "\n",
    "# -- 中间层 --\n",
    "class MiddleLayer:\n",
    "    def __init__(self, n_upper, n):  # 初始化设置\n",
    "        self.w = wb_width * np.random.randn(n_upper, n)  # 权重（矩阵）\n",
    "        self.b = wb_width * np.random.randn(n)  # 偏置（向量）\n",
    "\n",
    "    def forward(self, x):  # 正向传播\n",
    "        self.x = x\n",
    "        u = np.dot(x, self.w) + self.b\n",
    "        self.y = 1/(1+np.exp(-u))  # Sigmoid函数\n",
    "    \n",
    "    def backward(self, grad_y):  # 反向传播\n",
    "        delta = grad_y * (1-self.y)*self.y  # Sigmoid函数的微分\n",
    "        \n",
    "        self.grad_w = np.dot(self.x.T, delta)\n",
    "        self.grad_b = np.sum(delta, axis=0)\n",
    "        \n",
    "        self.grad_x = np.dot(delta, self.w.T) \n",
    "        \n",
    "    def update(self, eta):  # 权重和偏置的更新\n",
    "        self.w -= eta * self.grad_w\n",
    "        self.b -= eta * self.grad_b\n",
    "\n",
    "# -- 输出层 --\n",
    "class OutputLayer:\n",
    "    def __init__(self, n_upper, n):  # 初始化设置\n",
    "        self.w = wb_width * np.random.randn(n_upper, n)  # 权重（矩阵）\n",
    "        self.b = wb_width * np.random.randn(n)  # 偏置（向量）\n",
    "    \n",
    "    def forward(self, x):  # 正向传播\n",
    "        self.x = x\n",
    "        u = np.dot(x, self.w) + self.b\n",
    "        self.y = u  # 恒等函数\n",
    "    \n",
    "    def backward(self, t):  # 反向传播\n",
    "        delta = self.y - t\n",
    "        \n",
    "        self.grad_w = np.dot(self.x.T, delta)\n",
    "        self.grad_b = np.sum(delta, axis=0)\n",
    "        \n",
    "        self.grad_x = np.dot(delta, self.w.T) \n",
    "\n",
    "    def update(self, eta):  # 权重和偏置的更新\n",
    "        self.w -= eta * self.grad_w\n",
    "        self.b -= eta * self.grad_b\n",
    "\n",
    "\n",
    "# -- 各个网络层的初始化 --\n",
    "middle_layer = MiddleLayer(n_in, n_mid)\n",
    "output_layer = OutputLayer(n_mid, n_out)\n",
    "\n",
    "# -- 学习 --\n",
    "for i in range(epoch):\n",
    "\n",
    "    # 随机打乱索引值\n",
    "    index_random = np.arange(n_data)\n",
    "    np.random.shuffle(index_random)\n",
    "    \n",
    "    # 用于结果的显示\n",
    "    total_error = 0\n",
    "    plot_x = []\n",
    "    plot_y = []\n",
    "    \n",
    "    for idx in index_random:\n",
    "        \n",
    "        x = input_data[idx:idx+1]  # 输入\n",
    "        t = correct_data[idx:idx+1]  # 正确答案\n",
    "        \n",
    "        # 正向传播\n",
    "        middle_layer.forward(x.reshape(1, 1))  # 将输入转换为矩阵\n",
    "        output_layer.forward(middle_layer.y)  \n",
    "\n",
    "        # 反向传播\n",
    "        output_layer.backward(t.reshape(1, 1))  # 将正确答案转换为矩阵\n",
    "        middle_layer.backward(output_layer.grad_x)\n",
    "        \n",
    "        # 权重和偏置的更新\n",
    "        middle_layer.update(eta)\n",
    "        output_layer.update(eta)\n",
    "        \n",
    "        if i%interval == 0:\n",
    "            \n",
    "            y = output_layer.y.reshape(-1)  # 将矩阵还原成向量\n",
    "\n",
    "            # 误差的计算\n",
    "            total_error += 1.0/2.0*np.sum(np.square(y - t))  # 平方和误差\n",
    "            \n",
    "            # 输出的记录\n",
    "            plot_x.append(x)\n",
    "            plot_y.append(y)\n",
    "            \n",
    "    if i%interval == 0:\n",
    "        \n",
    "        # 用图表显示输出\n",
    "        plt.plot(input_data, correct_data, linestyle=\"dashed\")\n",
    "        plt.scatter(plot_x, plot_y, marker=\"+\")\n",
    "        plt.show()\n",
    "        \n",
    "        # 显示epoch次数和误差\n",
    "        print(\"Epoch:\" + str(i) + \"/\" + str(epoch), \"Error:\" + str(total_error/n_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}